{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S05 - Text Classification: Logistic Regression & Naive Bayes\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (Easy)\n",
    "Convert texts to Bag-of-Words representation using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['film' 'great' 'is' 'love' 'movie' 'of' 'terrible' 'this' 'time' 'waste']\n",
      "BoW Matrix:\n",
      " [[0 0 0 1 1 0 0 1 0 0]\n",
      " [0 0 1 0 1 0 1 1 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"I love this movie\", \"This movie is terrible\", \"Great film!\", \"Waste of time\"]\n",
    "\n",
    "# Create BoW representation\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(texts)\n",
    "#  We get feature names, this are the unique words in our text\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# We convert BoW matrix to array and print it\n",
    "# In the BoW matrix, each row corresponds to a document and each column corresponds to a unique word. \n",
    "# The values in the matrix represent the count of each word in the respective document.\n",
    "bow_array = bow_matrix.toarray()\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"BoW Matrix:\\n\", bow_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (Easy)\n",
    "Convert the same texts to TF-IDF representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Names: ['film' 'great' 'is' 'love' 'movie' 'of' 'terrible' 'this' 'time' 'waste']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.         0.         0.66767854 0.52640543 0.\n",
      "  0.         0.52640543 0.         0.        ]\n",
      " [0.         0.         0.55528266 0.         0.43779123 0.\n",
      "  0.55528266 0.43779123 0.         0.        ]\n",
      " [0.70710678 0.70710678 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.57735027\n",
      "  0.         0.         0.57735027 0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TF-IDF representation\n",
    "# We have to do the same as before but with TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "# We get feature names, this are the unique words in our text\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# We convert TF-IDF matrix to array and print it\n",
    "# In the TF-IDF matrix, each row corresponds to a document and each column corresponds to a unique word.\n",
    "# The values in the matrix represent the TF-IDF score of each word in the respective document.\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "print(\"TF-IDF Feature Names:\", tfidf_feature_names)\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 (Medium)\n",
    "Train a Naive Bayes classifier for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 0]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "texts = [\"I love this movie\", \"Great film\", \"Excellent acting\", \"Best movie ever\",\n",
    "         \"Terrible movie\", \"Waste of time\", \"Awful acting\", \"Worst film\"]\n",
    "labels = [1, 1, 1, 1, 0, 0, 0, 0]  # 1=positive, 0=negative\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# We predict the labels for the test set and print them\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted labels:\", y_pred)\n",
    "\n",
    "# We print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 (Medium)\n",
    "Train a Logistic Regression classifier and compare with Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Predicted labels: [0 0]\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\carid\\Desktop\\UIE\\3º\\SEGUNDO CUATRIMESTRE\\Procesamiento del Lenguaje\\procesamiento\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression and compare accuracy with Naive Bayes\n",
    "# We have to do the same as before but with LogisticRegression in this case\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_pred = logistic_model.predict(X_test)\n",
    "print(\"Logistic Regression Predicted labels:\", logistic_pred)\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, logistic_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 (Hard - Research)\n",
    "Implement Naive Bayes from scratch (without sklearn) for text classification.\n",
    "\n",
    "*Hint: Use log probabilities to avoid underflow. Research: P(c|d) ∝ P(c) × Π P(w|c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for 'I love this film': 0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.63      0.62      0.62         8\n",
      "weighted avg       0.63      0.62      0.62         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement Naive Bayes from scratch (without sklearn) for text classification.\n",
    "# Hint: Use log probabilities to avoid underflow. Research: P(c|d) ∝ P(c) × Π P(w|c)*\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.word_probs = defaultdict(dict)\n",
    "    \n",
    "    def fit(self, texts, labels):\n",
    "        # We calculate class probabilities\n",
    "        label_counts = Counter(labels)\n",
    "        total_count = len(labels)\n",
    "        self.class_probs = {label: count / total_count for label, count in label_counts.items()}\n",
    "        \n",
    "        # We calculate word probabilities for each class\n",
    "        word_counts = defaultdict(Counter)\n",
    "        for text, label in zip(texts, labels):\n",
    "            words = text.split()\n",
    "            word_counts[label].update(words)\n",
    "        \n",
    "        for label, counts in word_counts.items():\n",
    "            total_words = sum(counts.values())\n",
    "            self.word_probs[label] = {word: (count + 1) / (total_words + len(counts)) for word, count in counts.items()}\n",
    "\n",
    "    \n",
    "    def predict(self, text):\n",
    "        words = text.split()\n",
    "        class_scores = {}\n",
    "        for label in self.class_probs:\n",
    "            # We start with the log of the class probability\n",
    "            class_scores[label] = math.log(self.class_probs[label])\n",
    "            for word in words:\n",
    "                # We add the log of the word probability, using Laplace smoothing\n",
    "                class_scores[label] += math.log(self.word_probs[label].get(word, 1 / (sum(self.word_probs[label].values()) + len(self.word_probs[label]))))\n",
    "        # We return the class with the highest score\n",
    "        return max(class_scores, key=class_scores.get)\n",
    "\n",
    "# We test our Naive Bayes implementation\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(texts, labels)\n",
    "test_text = \"I love this film\"\n",
    "predicted_label = nb_classifier.predict(test_text)\n",
    "print(f\"Predicted label for '{test_text}': {predicted_label}\")\n",
    "\n",
    "# We evaluate our Naive Bayes implementation on the test set\n",
    "predicted_labels = [nb_classifier.predict(text) for text in texts]\n",
    "print(\"Classification Report:\\n\", classification_report(labels, predicted_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procesamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
