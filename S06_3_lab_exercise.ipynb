{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc524e1",
   "metadata": {},
   "source": [
    "# NLP Practical Exam — Text Processing + Language Modeling (90 minutes)\n",
    "\n",
    "**Instructions**\n",
    "- Work in this notebook only.\n",
    "- Write short, clear comments to justify *tool choices* (regex vs NLTK, etc.).\n",
    "- Do **not** use external NLP libraries beyond **NLTK**, **NumPy**, **PyTorch** (PyTorch not needed here).\n",
    "- Keep outputs readable (print key variables).\n",
    "\n",
    "**Total: 10 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a16ffbb",
   "metadata": {},
   "source": [
    "## Given text\n",
    "\n",
    "```python\n",
    "text = (\"In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona. He is 1.86m tall and met with researchers from U.P.C. and U.N.E.S.C.O. A report valued the project at $3.2 billion.\")\n",
    "```\n",
    "\n",
    "> Treat the text as *synthetic exam data* (no fact-checking needed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f16d8e",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. **(1 pt)** Sentence splitting using **regex + NLTK**.\n",
    "2. **(1 pt)** Regex normalization: acronyms, height meters→centimeters, money `$X.Y billion` → `x point y billion` (words).\n",
    "3. **(1 pt)** Lowercase **except** proper nouns; join multiword proper nouns with underscore (e.g., `Sam Altman → Sam_Altman`). Keep acronyms uppercase.\n",
    "4. **(1 pt)** Tokenize (tool of your choice).\n",
    "5. **(1 pt)** Remove stopwords (tool of your choice); keep entity tokens.\n",
    "6. **(1 pt)** Create bigrams with pure Python.\n",
    "7. **(2 pt)** Build a bigram LM (MLE) and `predict_next(prev_word, top_k=3)`.\n",
    "\n",
    "8. **(2 pt)** Implement a simple **BPE** on: `corpus = \"low lower newest widest\"` (≥5 merges or until no merges).\n",
    "9. **(1 pt)** Compute Accuracy/Precision/Recall/F1 for an invented confusion matrix (explain with comments).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4f7ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona. He is 1.86m tall and met with researchers from U.P.C. and U.N.E.S.C.O. A report valued the project at $3.2 billion.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# NLTK downloads (safe to run multiple times)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = (\"In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona. \"\n",
    "        \"He is 1.86m tall and met with researchers from U.P.C. and U.N.E.S.C.O. \"\n",
    "        \"A report valued the project at $3.2 billion.\")\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c9bdf",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2182c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona.', 'He is 1.86m tall and met with researchers from U.P.C. and U.N.E.S.C.O. A report valued the project at $3.2 billion.']\n"
     ]
    }
   ],
   "source": [
    "# Q1 (1 pt): Sentence splitting (regex + NLTK)\n",
    "# - Use regex to protect acronyms like U.P.C. so they don't break sentence boundaries.\n",
    "# - Then use nltk.sent_tokenize.\n",
    "#\n",
    "# Return: sentences (list of strings)\n",
    "\n",
    "# TODO: implement protect_acronym_dots and restore_acronym_dots (or equivalent)\n",
    "# TODO: apply sent_tokenize\n",
    "\n",
    "# First, I will implement the function to protect acronyms\n",
    "def protect_acronym_dots(text):\n",
    "    # This function replaces the dots in acronyms with a placeholder.\n",
    "    # We need to use lambda to ensure that we only replace the dots in  full acronyms and not in other contexts.\n",
    "    text = re.sub(r\"\\b([A-Z]\\.)+\", lambda m: m.group(0).replace(\".\", \"<DOT>\"), text)\n",
    "    # We also need to protect decimal numbers to avoid breaking them into sentences\n",
    "    text = re.sub(r\"\\b(\\d+)\\.(\\d+)\", r\"\\1<DOT>\\2\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def restore_acronym_dots(text):\n",
    "    # This function restores the dots in acronyms by replacing the placeholder back to dots.\n",
    "    return text.replace(\"<DOT>\", \".\")\n",
    "\n",
    "# Now, I will apply the protect_acronym_dots function to the text\n",
    "protected_text = protect_acronym_dots(text)\n",
    "\n",
    "# Next, I will use nltk.sent_tokenize to split the protected text into sentences\n",
    "sentences = sent_tokenize(protected_text)\n",
    "\n",
    "# Restore the acronym dots in each sentence\n",
    "sentences = [restore_acronym_dots(sentence) for sentence in sentences]\n",
    "\n",
    "# Finally, I will print the final sentences\n",
    "    \n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0cb6c",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec76b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona. He is 186 centimeters tall and met with researchers from UPC and UNESCO A report valued the project at threepointtwo billion.\n"
     ]
    }
   ],
   "source": [
    "# Q2 (1 pt): Regex normalization\n",
    "# Convert:\n",
    "#  - U.P.C. -> UPC, U.N.E.S.C.O. -> UNESCO (general rule: remove dots in acronyms)\n",
    "#  - 1.86m -> 186 centimeters (general: X.YZm -> int(round(float(X.YZ)*100)) centimeters)\n",
    "#  - $3.2 billion -> three point two billion  (digits 0-9 are enough)\n",
    "#\n",
    "# Return: text_norm\n",
    "def normalize_text(text):\n",
    "    # We remove dots in acronyms (e.g., U.P.C. -> UPC)\n",
    "    text = re.sub(r\"\\b([A-Z]\\.)+\", lambda m: m.group(0).replace(\".\", \"\"), text)\n",
    "    \n",
    "    # We convert meters to centimeters\n",
    "    # I create a function to handle the conversion from meters to centimeters, which will be used in the re.sub function. \n",
    "    def meters_to_cm(match):\n",
    "        meters = float(match.group(1))\n",
    "        cm = int(round(meters * 100))\n",
    "        return f\"{cm} centimeters\"\n",
    "    text = re.sub(r\"(\\d+\\.\\d+)m\\b\", meters_to_cm, text)\n",
    "       \n",
    "    # We convert digits to words for amounts in billions with another function\n",
    "    def dollar_to_words(match):\n",
    "        number = match.group(1)\n",
    "        unit = match.group(2)\n",
    "        # I create a dictionary to map digits to their word representations.\n",
    "        digit_map = {\"0\": \"zero\", \"1\": \"one\", \"2\": \"two\", \"3\": \"three\", \"4\": \"four\",\n",
    "                     \"5\": \"five\", \"6\": \"six\", \"7\": \"seven\", \"8\": \"eight\", \"9\": \"nine\"}\n",
    "        # We convert each character\n",
    "        words = \"\".join(\"point\" if c == '.' else digit_map.get(c, c) for c in number)\n",
    "        return f\"{words} {unit}\"\n",
    "    text = re.sub(r\"\\$(\\d+\\.?\\d*)\\s+(billion|million|thousand)\", dollar_to_words, text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = (\"In mid-February 2026, the CEO of OpenAI, Sam Altman, visited Barcelona. \"\n",
    "        \"He is 1.86m tall and met with researchers from U.P.C. and U.N.E.S.C.O. \"\n",
    "        \"A report valued the project at $3.2 billion.\")\n",
    "\n",
    "text_norm = normalize_text(text)\n",
    "print(text_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbaf89",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In mid-february 2026 , the CEO of OpenAI , Sam_Altman , visited Barcelona . He is 186 centimeters tall and met with researchers from UPC and UNESCO a report valued the project at threepointtwo billion .\n"
     ]
    }
   ],
   "source": [
    "# Q3 (1 pt): Lowercase except proper nouns + underscore multiword proper nouns\n",
    "# Requirements:\n",
    "# - Convert to lowercase except:\n",
    "#   - Acronyms (ALL CAPS) stay uppercase (e.g., UNESCO, UPC, CEO)\n",
    "#   - MixedCase tokens stay as-is (e.g., OpenAI)\n",
    "#   - Multiword proper nouns joined with underscore (Sam Altman -> Sam_Altman) and preserved\n",
    "#\n",
    "# Return: text_case\n",
    "\n",
    "\n",
    "text_case = None\n",
    "\n",
    "# print(text_case)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eaf848",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecd9c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 (1 pt): Tokenization\n",
    "# Use a tokenizer of your choice (e.g., nltk.word_tokenize).\n",
    "# Return: tokens (list)\n",
    "\n",
    "tokens = None\n",
    "\n",
    "# print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4e851",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b208cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 (1 pt): Stopword removal\n",
    "# - Remove English stopwords\n",
    "# - Do NOT remove entity tokens like OpenAI, Sam_Altman, Barcelona, UNESCO, UPC\n",
    "# Return: tokens_nostop\n",
    "\n",
    "tokens_nostop = None\n",
    "\n",
    "# print(tokens_nostop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab209a7",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94862b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 (1 pt): Bigrams with pure Python (no NLTK bigrams helper)\n",
    "# Return: bigrams = [(w1, w2), ...]\n",
    "\n",
    "bigrams = None\n",
    "\n",
    "# print(bigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885728fc",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51fab00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 (2 pt): Bigram Language Model + next-word prediction\n",
    "# Build:\n",
    "# - bigram_counts[(w1,w2)]\n",
    "# - context_counts[w1]\n",
    "# - model[w1][w2] = P(w2|w1) = count(w1,w2)/count(w1)\n",
    "#\n",
    "# Then implement:\n",
    "# def predict_next(prev_word, model, top_k=3): -> list[(next_word, prob)] sorted\n",
    "\n",
    "bigram_counts = None\n",
    "context_counts = None\n",
    "model = None\n",
    "\n",
    "def predict_next(prev_word, model, top_k=3):\n",
    "    # TODO\n",
    "    return None\n",
    "\n",
    "# Example:\n",
    "# print(predict_next(\"OpenAI\", model, top_k=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc35060",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e4e2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 (2 pt): Simple BPE (Byte Pair Encoding) on a tiny corpus\n",
    "corpus = \"low lower newest widest\"\n",
    "\n",
    "# Requirements:\n",
    "# - Represent each word as characters + </w>\n",
    "# - Compute pair frequencies (weighted by word frequency)\n",
    "# - Merge most frequent pair\n",
    "# - Do at least 5 merges (or stop if no pairs)\n",
    "#\n",
    "# Deliver:\n",
    "# - merges: list of merges in order\n",
    "# - final segmented version of each word\n",
    "\n",
    "merges = None\n",
    "\n",
    "# TODO: implement BPE helper functions:\n",
    "# - get_vocab_from_corpus\n",
    "# - get_pair_frequencies\n",
    "# - merge_pair_in_vocab\n",
    "\n",
    "# print(merges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d34fa",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47c22e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 (1 pt): Metrics — Accuracy, Precision, Recall, F1\n",
    "# Invent a confusion matrix (TP, FP, FN, TN) and compute metrics.\n",
    "# Explain each formula briefly in comments.\n",
    "\n",
    "TP = None\n",
    "FP = None\n",
    "FN = None\n",
    "TN = None\n",
    "\n",
    "accuracy = None\n",
    "precision = None\n",
    "recall = None\n",
    "f1 = None\n",
    "\n",
    "# print(accuracy, precision, recall, f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procesamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
